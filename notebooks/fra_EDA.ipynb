{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "# base data directory\n",
    "base_dir = '../data/'\n",
    "\n",
    "# raw data directory\n",
    "raw_dir = os.path.join(base_dir, 'raw/')\n",
    "\n",
    "# iterim data directory\n",
    "interim_dir = os.path.join(base_dir, 'interim/')\n",
    "\n",
    "# processed data directory\n",
    "proc_dir =  os.path.join(base_dir, 'processed/')\n",
    "\n",
    "# splits \n",
    "splits = ['bal_train/', 'eval/', 'unbal_train/']\n",
    "\n",
    "# segments files\n",
    "segments = ['balanced_train_segments.csv', 'unbalanced_train_segments.csv', 'eval_segments.csv']\n",
    "\n",
    "# labels file path\n",
    "labels_path = os.path.join(raw_dir, 'class_labels_indices.csv')\n",
    "\n",
    "# onthology file path\n",
    "ont_path = os.path.join(raw_dir, 'ontology.json')\n",
    "\n",
    "# [raw/interim/processed][split]\n",
    "data_path = {'raw': {}, 'interim': {}, 'processed': {}}  \n",
    "\n",
    "# [raw/interim/processed][split]\n",
    "data_dir = {'raw': {}, 'interim': {}, 'processed': {}}  \n",
    "\n",
    "for i, seg in enumerate(splits):\n",
    "    \n",
    "    seg_rm = seg.replace('/', '')\n",
    "    \n",
    "    raw = os.path.join(raw_dir, splits[i])\n",
    "    data_dir['raw'][seg_rm] = raw\n",
    "    raw = os.path.join(raw, segments[i])\n",
    "    data_path['raw'][seg_rm] = raw\n",
    "    \n",
    "    interim = os.path.join(interim_dir, splits[i])\n",
    "    data_dir['interim'][seg_rm] = interim\n",
    "    interim = os.path.join(interim, segments[i])\n",
    "    data_path['interim'][seg_rm] = interim\n",
    "    \n",
    "    processed = os.path.join(proc_dir, splits[i])\n",
    "    data_dir['processed'][seg_rm] = processed\n",
    "    processed = os.path.join(processed, segments[i])\n",
    "    data_path['processed'][seg_rm] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file: ../data/raw/bal_train/balanced_train_segments.csv\n",
      "is in the directory: ../data/raw/bal_train/\n"
     ]
    }
   ],
   "source": [
    "print(f\"data file: {data_path['raw']['bal_train']}\")\n",
    "print(f\"is in the directory: {data_dir['raw']['bal_train']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been cleaned and saved in ../data/interim/bal_train/\n"
     ]
    }
   ],
   "source": [
    "# Read the file and replace problematic commas\n",
    "with open(data_path['raw']['bal_train'], \"r\", encoding=\"utf-8\") as f:\n",
    "    # Read all lines from the input file\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    # Remove the first two rows\n",
    "    lines = lines[2:]\n",
    "    \n",
    "    # Remove the first two characters (\"# \") from the third row (now the first row after removing the first two)\n",
    "    lines[0] = lines[0][2:]\n",
    "\n",
    "    # Replace commas that are NOT followed by a space\n",
    "    fixed_lines = [re.sub(r',(?! )', ';', line) for line in lines]\n",
    "\n",
    "# Save the modified file\n",
    "with open(data_path['interim']['bal_train'], \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(fixed_lines)\n",
    "\n",
    "print(f\"File has been cleaned and saved in {data_dir['interim']['bal_train']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YTID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " start_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " end_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " positive_labels",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bdfeeb93-bf05-46bc-bfaa-748092d3c1e5",
       "rows": [
        [
         "0",
         "--PJHxphWEs",
         "30.0",
         "40.0",
         " \"/m/09x0r;/t/dd00088\""
        ],
        [
         "1",
         "--ZhevVpy1s",
         "50.0",
         "60.0",
         " \"/m/012xff\""
        ],
        [
         "2",
         "--aE2O5G5WE",
         "0.0",
         "10.0",
         " \"/m/03fwl;/m/04rlf;/m/09x0r\""
        ],
        [
         "3",
         "--aO5cdqSAg",
         "30.0",
         "40.0",
         " \"/t/dd00003;/t/dd00005\""
        ],
        [
         "4",
         "--aaILOrkII",
         "200.0",
         "210.0",
         " \"/m/032s66;/m/073cg4\""
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--PJHxphWEs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/m/09x0r;/t/dd00088\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--ZhevVpy1s</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>\"/m/012xff\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--aE2O5G5WE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"/m/03fwl;/m/04rlf;/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--aO5cdqSAg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/t/dd00003;/t/dd00005\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--aaILOrkII</td>\n",
       "      <td>200.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>\"/m/032s66;/m/073cg4\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID   start_seconds   end_seconds                positive_labels\n",
       "0  --PJHxphWEs            30.0          40.0          \"/m/09x0r;/t/dd00088\"\n",
       "1  --ZhevVpy1s            50.0          60.0                    \"/m/012xff\"\n",
       "2  --aE2O5G5WE             0.0          10.0   \"/m/03fwl;/m/04rlf;/m/09x0r\"\n",
       "3  --aO5cdqSAg            30.0          40.0        \"/t/dd00003;/t/dd00005\"\n",
       "4  --aaILOrkII           200.0         210.0          \"/m/032s66;/m/073cg4\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: Read the modified file\n",
    "df = pd.read_csv(\n",
    "    data_path['interim']['bal_train'],\n",
    "    quotechar = '\"',\n",
    "    delimiter = \",\",\n",
    "    quoting = 1,\n",
    "    index_col = 0,\n",
    "    header = 0,\n",
    "    dtype = {'positive_labels': str} \n",
    ")\n",
    "\n",
    "# keep the index as a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# drop it\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/interim/bal_train/'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(data_dir['raw']['bal_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecord files list for bal_train\n",
    "split_dir = data_dir['raw']['bal_train']\n",
    "tfrecord_files = [os.path.join(split_dir, f) for f in os.listdir(split_dir) if f.endswith('.tfrecord')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_tfrecord_n(file_path, n):\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    for i, raw_record in enumerate(raw_dataset.take(n), start=1):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        print(f\"Features del registro numero {i} de {file_name}:\")\n",
    "        for key, feature in example.features.feature.items():\n",
    "            if feature.HasField(\"bytes_list\"):\n",
    "                value = feature.bytes_list.value[0].decode('utf-8') if feature.bytes_list.value else \"\"\n",
    "            elif feature.HasField(\"float_list\"):\n",
    "                value = feature.float_list.value[0] if feature.float_list.value else 0.0\n",
    "            elif feature.HasField(\"int64_list\"):\n",
    "                value = feature.int64_list.value[0] if feature.int64_list.value else 0\n",
    "            else:\n",
    "                value = \"Unknown Type\"\n",
    "            print(f'\"{key}\": {value}')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect an arbitrary record from the tfrecord list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features del registro numero 1 de --.tfrecord:\n",
      "\"labels\": 399\n",
      "\"video_id\": --cB2ZVjpnA\n",
      "\"start_time_seconds\": 30.0\n",
      "\"end_time_seconds\": 40.0\n",
      "\n",
      "Features del registro numero 2 de --.tfrecord:\n",
      "\"end_time_seconds\": 40.0\n",
      "\"video_id\": --PJHxphWEs\n",
      "\"start_time_seconds\": 30.0\n",
      "\"labels\": 0\n",
      "\n",
      "Features del registro numero 3 de --.tfrecord:\n",
      "\"end_time_seconds\": 40.0\n",
      "\"video_id\": --ekDLDTUXA\n",
      "\"start_time_seconds\": 30.0\n",
      "\"labels\": 27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = tfrecord_files[0]\n",
    "inspect_tfrecord_n(file_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YTID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " start_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " end_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " positive_labels",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "707bbf58-c4f4-4a36-9918-cb903a55e526",
       "rows": [
        [
         "5",
         "--cB2ZVjpnA",
         "30.0",
         "40.0",
         " \"/m/01y3hg\""
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/m/01y3hg\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID   start_seconds   end_seconds  positive_labels\n",
       "5  --cB2ZVjpnA            30.0          40.0      \"/m/01y3hg\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = df[df['YTID'].str.contains('--cB2ZVjpnA')] \n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/m/0dgw9r',\n",
       " 'name': 'Human sounds',\n",
       " 'description': 'Sounds produced by the human body through the actions of the individual.',\n",
       " 'citation_uri': '',\n",
       " 'positive_examples': [],\n",
       " 'child_ids': ['/m/09l8g',\n",
       "  '/m/01w250',\n",
       "  '/m/09hlz4',\n",
       "  '/m/0bpl036',\n",
       "  '/m/0160x5',\n",
       "  '/m/0k65p',\n",
       "  '/m/01jg02',\n",
       "  '/m/04xp5v',\n",
       "  '/t/dd00012'],\n",
       " 'restrictions': ['abstract']}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Open and read the JSON onthology file\n",
    "with open(ont_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target '/m/01y3hg' was found in the following names: ['Alarm', 'Smoke detector, smoke alarm']\n"
     ]
    }
   ],
   "source": [
    "# Target string to search for\n",
    "target_string = \"/m/01y3hg\"\n",
    "\n",
    "# Function to search for the target string in 'id' and 'child_ids'\n",
    "def search_data(data, target):\n",
    "    results = []\n",
    "    for item in data:\n",
    "        # Check if the target matches the 'id' field\n",
    "        if item['id'] == target:\n",
    "            results.append(item['name'])\n",
    "        # Check if the target matches any of the 'child_ids'\n",
    "        if target in item.get('child_ids', []):\n",
    "            results.append(item['name'])\n",
    "    return results\n",
    "\n",
    "# Perform the search\n",
    "matching_names = search_data(data, target_string)\n",
    "\n",
    "# Print the results\n",
    "if matching_names:\n",
    "    print(f\"The target '{target_string}' was found in the following names: {matching_names}\")\n",
    "else:\n",
    "    print(f\"The target '{target_string}' was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features del registro numero 1 de \"--.tfrecord\", con \"video_id\" de --cB2ZVjpnA tiene en la columna de \"positive_labels\" del archivo segments.csv, un valor de  \"/m/01y3hg\", el cual al buscarlo en el diccionario ontology.json obtenemos que tiene los valores de \"['Alarm', 'Smoke detector, smoke alarm']\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
