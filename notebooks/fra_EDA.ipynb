{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/bal_train/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file paths\n",
    "\n",
    "## base data directory\n",
    "base_dir = \"../data/\"\n",
    "\n",
    "## raw data directory\n",
    "raw_dir = \"raw/\"\n",
    "\n",
    "## datas directories\n",
    "bal_dir = [\"bal_train/\", \"eval/\", \"unbal_train/\"]\n",
    "os.path.join(base_dir, raw_dir, bal_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "## base data directory\n",
    "base_dir = '../data/'\n",
    "\n",
    "## raw data directory\n",
    "raw_dir = 'raw/'\n",
    "\n",
    "## iterim data directory\n",
    "interim_dir = 'interim/'\n",
    "\n",
    "## processed data directory\n",
    "proc_dir = 'processed/'\n",
    "\n",
    "## splits directories\n",
    "split_dir = ['bal_train/', 'eval/', 'unbal_train/']\n",
    "\n",
    "###\n",
    "#seg = 'segments.csv'\n",
    "seg_dir = ['balanced_train_segments.csv', 'unbalanced_train_segments.csv', 'eval_segments.csv']\n",
    "\n",
    "### onthology directory\n",
    "ont_dir = 'ontology.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "raw_data = os.path.join(base_dir, raw_dir, split_dir[0])\n",
    "interim_data = os.path.join(base_dir, interim_dir, split_dir[0])\n",
    "processed_data = os.path.join(base_dir, proc_dir, split_dir[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been cleaned and saved to ../data/interim/bal_train/bal_train_seg.csv\n"
     ]
    }
   ],
   "source": [
    "bal_seg = os.path.join(raw_data, seg_dir[0])\n",
    "seg_int = os.path.join(base_dir, interim_dir, split_dir[0], \"bal_train_seg.csv\")\n",
    "\n",
    "# Step 1: Read the file and replace problematic commas\n",
    "with open(bal_seg, \"r\", encoding=\"utf-8\") as f:\n",
    "    # Read all lines from the input file\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    # Remove the first two rows\n",
    "    lines = lines[2:]\n",
    "    \n",
    "    # Remove the first two characters (\"# \") from the third row (now the first row after removing the first two)\n",
    "    lines[0] = lines[0][2:]\n",
    "\n",
    "    # Replace commas that are NOT followed by a space\n",
    "    fixed_lines = [re.sub(r',(?! )', ';', line) for line in lines]\n",
    "\n",
    "# Step 2: Save the modified file\n",
    "with open(seg_int, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(fixed_lines)\n",
    "\n",
    "print(f\"File has been cleaned and saved to {seg_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YTID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " start_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " end_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " positive_labels",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "74acc156-3911-4791-b6ad-531ba0aeb0a8",
       "rows": [
        [
         "0",
         "--PJHxphWEs",
         "30.0",
         "40.0",
         " \"/m/09x0r;/t/dd00088\""
        ],
        [
         "1",
         "--ZhevVpy1s",
         "50.0",
         "60.0",
         " \"/m/012xff\""
        ],
        [
         "2",
         "--aE2O5G5WE",
         "0.0",
         "10.0",
         " \"/m/03fwl;/m/04rlf;/m/09x0r\""
        ],
        [
         "3",
         "--aO5cdqSAg",
         "30.0",
         "40.0",
         " \"/t/dd00003;/t/dd00005\""
        ],
        [
         "4",
         "--aaILOrkII",
         "200.0",
         "210.0",
         " \"/m/032s66;/m/073cg4\""
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--PJHxphWEs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/m/09x0r;/t/dd00088\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--ZhevVpy1s</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>\"/m/012xff\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--aE2O5G5WE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"/m/03fwl;/m/04rlf;/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--aO5cdqSAg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/t/dd00003;/t/dd00005\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--aaILOrkII</td>\n",
       "      <td>200.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>\"/m/032s66;/m/073cg4\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID   start_seconds   end_seconds                positive_labels\n",
       "0  --PJHxphWEs            30.0          40.0          \"/m/09x0r;/t/dd00088\"\n",
       "1  --ZhevVpy1s            50.0          60.0                    \"/m/012xff\"\n",
       "2  --aE2O5G5WE             0.0          10.0   \"/m/03fwl;/m/04rlf;/m/09x0r\"\n",
       "3  --aO5cdqSAg            30.0          40.0        \"/t/dd00003;/t/dd00005\"\n",
       "4  --aaILOrkII           200.0         210.0          \"/m/032s66;/m/073cg4\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: Read the modified file\n",
    "df = pd.read_csv(\n",
    "    seg_int,\n",
    "    quotechar = '\"',\n",
    "    delimiter = \",\",\n",
    "    quoting = 1,\n",
    "    index_col = 0,\n",
    "    header = 0,\n",
    "    dtype = {'positive_labels': str} \n",
    ")\n",
    "\n",
    "# keep the index as a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# drop it\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/bal_train/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(base_dir, raw_dir, split_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecord files list\n",
    "for data in split_dir:\n",
    "    files = os.path.join(base_dir, raw_dir, split_dir[0])\n",
    "    tfrecord_files = [os.path.join(files, f) for f in os.listdir(files) if f.endswith('.tfrecord')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_tfrecord_n(file_path, n):\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    for i, raw_record in enumerate(raw_dataset.take(n), start=1):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        print(f\"Features del registro numero {i} de {file_name}:\")\n",
    "        for key, feature in example.features.feature.items():\n",
    "            if feature.HasField(\"bytes_list\"):\n",
    "                value = feature.bytes_list.value[0].decode('utf-8') if feature.bytes_list.value else \"\"\n",
    "            elif feature.HasField(\"float_list\"):\n",
    "                value = feature.float_list.value[0] if feature.float_list.value else 0.0\n",
    "            elif feature.HasField(\"int64_list\"):\n",
    "                value = feature.int64_list.value[0] if feature.int64_list.value else 0\n",
    "            else:\n",
    "                value = \"Unknown Type\"\n",
    "            print(f'\"{key}\": {value}')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect an arbitrary record from the tfrecord list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features del registro numero 1 de --.tfrecord:\n",
      "\"labels\": 399\n",
      "\"video_id\": --cB2ZVjpnA\n",
      "\"start_time_seconds\": 30.0\n",
      "\"end_time_seconds\": 40.0\n",
      "\n",
      "Features del registro numero 2 de --.tfrecord:\n",
      "\"end_time_seconds\": 40.0\n",
      "\"video_id\": --PJHxphWEs\n",
      "\"start_time_seconds\": 30.0\n",
      "\"labels\": 0\n",
      "\n",
      "Features del registro numero 3 de --.tfrecord:\n",
      "\"end_time_seconds\": 40.0\n",
      "\"video_id\": --ekDLDTUXA\n",
      "\"start_time_seconds\": 30.0\n",
      "\"labels\": 27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = tfrecord_files[0]\n",
    "inspect_tfrecord_n(file_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YTID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " start_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " end_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " positive_labels",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ee0927f5-8698-4733-967d-d1deecf6582c",
       "rows": [
        [
         "5",
         "--cB2ZVjpnA",
         "30.0",
         "40.0",
         " \"/m/01y3hg\""
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/m/01y3hg\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID   start_seconds   end_seconds  positive_labels\n",
       "5  --cB2ZVjpnA            30.0          40.0      \"/m/01y3hg\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = df[df['YTID'].str.contains('--cB2ZVjpnA')] \n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/m/0dgw9r',\n",
       " 'name': 'Human sounds',\n",
       " 'description': 'Sounds produced by the human body through the actions of the individual.',\n",
       " 'citation_uri': '',\n",
       " 'positive_examples': [],\n",
       " 'child_ids': ['/m/09l8g',\n",
       "  '/m/01w250',\n",
       "  '/m/09hlz4',\n",
       "  '/m/0bpl036',\n",
       "  '/m/0160x5',\n",
       "  '/m/0k65p',\n",
       "  '/m/01jg02',\n",
       "  '/m/04xp5v',\n",
       "  '/t/dd00012'],\n",
       " 'restrictions': ['abstract']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dir = os.path.join(base_dir, raw_dir, ont_dir)\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(json_dir, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target '/m/01y3hg' was found in the following names: ['Alarm', 'Smoke detector, smoke alarm']\n"
     ]
    }
   ],
   "source": [
    "# Target string to search for\n",
    "target_string = \"/m/01y3hg\"\n",
    "\n",
    "# Function to search for the target string in 'id' and 'child_ids'\n",
    "def search_data(data, target):\n",
    "    results = []\n",
    "    for item in data:\n",
    "        # Check if the target matches the 'id' field\n",
    "        if item['id'] == target:\n",
    "            results.append(item['name'])\n",
    "        # Check if the target matches any of the 'child_ids'\n",
    "        if target in item.get('child_ids', []):\n",
    "            results.append(item['name'])\n",
    "    return results\n",
    "\n",
    "# Perform the search\n",
    "matching_names = search_data(data, target_string)\n",
    "\n",
    "# Print the results\n",
    "if matching_names:\n",
    "    print(f\"The target '{target_string}' was found in the following names: {matching_names}\")\n",
    "else:\n",
    "    print(f\"The target '{target_string}' was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features del registro numero 1 de \"--.tfrecord\", con \"video_id\" de --cB2ZVjpnA tiene en la columna de \"positive_labels\" del archivo segments.csv, un valor de  \"/m/01y3hg\", el cual al buscarlo en el diccionario ontology.json obtenemos que tiene los valores de \"['Alarm', 'Smoke detector, smoke alarm']\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
