{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e345c808",
   "metadata": {},
   "source": [
    "Registro de Modelos en DagsHub - Audio Classification\n",
    "\n",
    "Este notebook entrena y registra modelos de clasificaci√≥n de audio en DagsHub, incluyendo:\n",
    "- Logistic Regression\n",
    "- Linear Support Vector Classifier\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db1aeb",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d811b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5fcb1",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d488ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base data directory\n",
    "base_dir = '../data/'\n",
    "\n",
    "# raw data directory\n",
    "raw_dir = os.path.join(base_dir, 'raw/')\n",
    "\n",
    "# interim data directory\n",
    "interim_dir = os.path.join(base_dir, 'interim/')\n",
    "\n",
    "# processed data directory\n",
    "proc_dir = os.path.join(base_dir, 'processed/')\n",
    "\n",
    "# splits \n",
    "splits = ['bal_train/', 'eval/', 'unbal_train/']\n",
    "\n",
    "# segments files\n",
    "segments = ['balanced_train_segments.csv', 'unbalanced_train_segments.csv', 'eval_segments.csv']\n",
    "\n",
    "# labels file path\n",
    "labels_path = os.path.join(raw_dir, 'class_labels_indices.csv')\n",
    "\n",
    "# ontology file path\n",
    "ont_path = os.path.join(raw_dir, 'ontology.json')\n",
    "\n",
    "# [raw/interim/processed][split]\n",
    "data_path = {'raw': {}, 'interim': {}, 'processed': {}}  \n",
    "data_dir = {'raw': {}, 'interim': {}, 'processed': {}}  \n",
    "\n",
    "for i, seg in enumerate(splits):\n",
    "    seg_rm = seg.replace('/', '')\n",
    "    \n",
    "    raw = os.path.join(raw_dir, splits[i])\n",
    "    data_dir['raw'][seg_rm] = raw\n",
    "    raw = os.path.join(raw, segments[i])\n",
    "    data_path['raw'][seg_rm] = raw\n",
    "    \n",
    "    interim = os.path.join(interim_dir, splits[i])\n",
    "    data_dir['interim'][seg_rm] = interim\n",
    "    interim = os.path.join(interim, segments[i])\n",
    "    data_path['interim'][seg_rm] = interim\n",
    "    \n",
    "    processed = os.path.join(proc_dir, splits[i])\n",
    "    data_dir['processed'][seg_rm] = processed\n",
    "    processed = os.path.join(processed, segments[i])\n",
    "    data_path['processed'][seg_rm] = processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63095dc",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0f989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def parse_music_example(example_proto, music_ids, id_labels_dict, seq_length=10):\n",
    "    \"\"\"Parse TFRecord example.\"\"\"\n",
    "    # Convert dict to constant tensor\n",
    "    id_labels_tensor = tf.constant(list(id_labels_dict.values()))\n",
    "\n",
    "    # Define features\n",
    "    context_features = {\n",
    "        \"video_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"labels\": tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    sequence_features = {\n",
    "        \"audio_embedding\": tf.io.FixedLenSequenceFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "    # Parse the example\n",
    "    context, sequences = tf.io.parse_single_sequence_example(\n",
    "        example_proto, \n",
    "        context_features=context_features, \n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "\n",
    "    # Process audio embeddings\n",
    "    audio_embeddings = tf.io.decode_raw(sequences['audio_embedding'], tf.uint8)\n",
    "    audio_embeddings = tf.reshape(audio_embeddings, [-1, 128])\n",
    "    audio_embeddings = (tf.cast(audio_embeddings, tf.float32) - 127.5) / 127.5\n",
    "    audio_embeddings = audio_embeddings[:seq_length]\n",
    "    padding = [[0, seq_length - tf.shape(audio_embeddings)[0]], [0, 0]]\n",
    "    audio_embeddings = tf.pad(audio_embeddings, padding)\n",
    "    audio_embeddings.set_shape([seq_length, 128])\n",
    "\n",
    "    # Process labels\n",
    "    labels = tf.sparse.to_dense(context['labels'])\n",
    "    id_labels = tf.gather(id_labels_tensor, labels)\n",
    "    \n",
    "    # Check if any label matches music_ids\n",
    "    is_music = tf.reduce_any(tf.equal(tf.expand_dims(id_labels, -1), music_ids))\n",
    "    \n",
    "    return audio_embeddings, tf.cast(is_music, tf.float32)\n",
    "\n",
    "def create_dataset(tfrecord_dir, music_ids, batch_size=32, seq_length=10, is_training=True):\n",
    "    \"\"\"Create TF dataset pipeline.\"\"\"\n",
    "    tfrecord_files = tf.io.gfile.glob(os.path.join(tfrecord_dir, \"*.tfrecord\"))\n",
    "    if not tfrecord_files:\n",
    "        raise ValueError(f\"No TFRecord files found in {tfrecord_dir}\")\n",
    "        \n",
    "    # Convert music_ids to tensor\n",
    "    music_ids_tensor = tf.constant([str(id) for id in music_ids], dtype=tf.string)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Parse examples\n",
    "    parse_fn = lambda x: parse_music_example(x, music_ids_tensor, id_labels_dict, seq_length)\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Shuffle if training\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    # Batch and prefetch\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd921dbd",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cd7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read balanced train segments\n",
    "with open(data_path['raw']['bal_train'], \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "fixed_rows = []\n",
    "for line in lines[3:]:  \n",
    "    parts = line.strip().split(\",\")  \n",
    "    if len(parts) >= 4:  \n",
    "        fixed_rows.append([parts[0], parts[1], parts[2], \",\".join(parts[3:])]) \n",
    "\n",
    "df_segments = pd.DataFrame(fixed_rows, columns=[\"YTID\", \"start_seconds\", \"end_seconds\", \"positive_labels\"])\n",
    "\n",
    "# Load ontology\n",
    "with open(ont_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_ontology = pd.DataFrame(data)\n",
    "\n",
    "# Create music labels\n",
    "keywords_column_name = [\"music\", \"musical\", \"song\", \"instrument\", \"singing\"]\n",
    "keywords_column_description = [\"music\", \"musical\", \"song\", \"singing\"]\n",
    "\n",
    "pattern_column_name = \"|\".join(keywords_column_name)\n",
    "pattern_column_description = \"|\".join(keywords_column_description)\n",
    "\n",
    "name_contains = df_ontology[\"name\"].str.lower().str.contains(pattern_column_name)\n",
    "description_contains = df_ontology[\"description\"].str.lower().str.contains(pattern_column_description, na=False)\n",
    "\n",
    "df_ontology[\"is_music\"] = (name_contains | description_contains).astype(int)\n",
    "\n",
    "# Load class labels\n",
    "df_class_labels_indices = pd.read_csv(labels_path)\n",
    "\n",
    "# Merge ontology and labels\n",
    "df_ontology_labels = pd.merge(df_class_labels_indices, df_ontology, left_on='mid', right_on='id', how='left')\n",
    "df_ontology_labels = df_ontology_labels.drop(columns=['mid', 'display_name'])\n",
    "id_labels_dict = df_ontology_labels.set_index('index')['id'].to_dict()\n",
    "df_ontology_labels.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cdf597",
   "metadata": {},
   "source": [
    "## Train, val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4386d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get music IDs\n",
    "music_ids = set(df_ontology_labels[df_ontology_labels[\"is_music\"] == 1][\"id\"].astype(str))\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = create_dataset(\n",
    "    tfrecord_dir=data_dir['raw']['bal_train'],\n",
    "    music_ids=music_ids,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Better way to get dataset size (without loading all data)\n",
    "def get_dataset_size(dataset):\n",
    "    return sum(1 for _ in dataset)\n",
    "\n",
    "# Split dataset\n",
    "dataset_size = get_dataset_size(full_dataset)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "train_ds = full_dataset.skip(val_size)\n",
    "val_ds = full_dataset.take(val_size)\n",
    "\n",
    "# Convert TF Dataset to numpy arrays\n",
    "def dataset_to_numpy(dataset):\n",
    "    X, y = [], []\n",
    "    for audio_emb, label in dataset.unbatch():\n",
    "        X.append(audio_emb.numpy().flatten())  # Flatten to [seq_length * 128]\n",
    "        y.append(label.numpy())\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = dataset_to_numpy(train_ds)\n",
    "X_val, y_val = dataset_to_numpy(val_ds)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Dimensionality reduction\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1e12c",
   "metadata": {},
   "source": [
    "## DagsHub init and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34995efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as felytz\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as felytz\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"felytz/waveled\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"felytz/waveled\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository felytz/waveled initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository felytz/waveled initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize DagsHub\n",
    "dagshub.init(repo_owner='felytz', repo_name='waveled', mlflow=True)\n",
    "mlflow.set_tracking_uri('https://dagshub.com/felytz/waveled.mlflow')\n",
    "\n",
    "def train_and_register_model(model, model_name, params, X_train, y_train, X_test, y_test, use_pca=False):\n",
    "    \"\"\"Train model with GridSearch and log to MLflow.\"\"\"\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log tags\n",
    "        mlflow.set_tag(\"model_type\", model_name)\n",
    "        mlflow.set_tag(\"dataset\", \"AudioSet\")\n",
    "        mlflow.set_tag(\"features\", \"PCA\" if use_pca else \"Original\")\n",
    "        \n",
    "        # Grid Search\n",
    "        grid = GridSearchCV(\n",
    "            model, \n",
    "            params, \n",
    "            cv=3, \n",
    "            scoring='f1_weighted', \n",
    "            n_jobs=-1, \n",
    "            verbose=1\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        # Get best model\n",
    "        best_model = grid.best_estimator_\n",
    "        \n",
    "        # Evaluation\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_params(grid.best_params_)\n",
    "        \n",
    "        # Log artifacts\n",
    "        mlflow.sklearn.log_model(best_model, model_name)\n",
    "        mlflow.log_dict(\n",
    "            classification_report(y_test, y_pred, output_dict=True), \n",
    "            \"classification_report.json\"\n",
    "        )\n",
    "        \n",
    "        # Log preprocessing models\n",
    "        if use_pca:\n",
    "            mlflow.sklearn.log_model(pca, \"pca_model\")\n",
    "        mlflow.sklearn.log_model(scaler, \"scaler_model\")\n",
    "        \n",
    "        print(f\"{model_name} - F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532bda0",
   "metadata": {},
   "source": [
    "## Models definition, training, and register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4f7902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 22:57:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/04 22:57:41 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/05/04 22:57:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/04 22:57:49 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/05/04 22:57:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_PCA - F1: 0.8588, Accuracy: 0.8580\n",
      "üèÉ View run LogisticRegression_PCA at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0/runs/e0f0e4cad21b49c1b5624580b5cc9460\n",
      "üß™ View experiment at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 22:58:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/04 22:58:12 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/05/04 22:58:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/04 22:58:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/05/04 22:58:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_PCA - F1: 0.8592, Accuracy: 0.8587\n",
      "üèÉ View run LinearSVC_PCA at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0/runs/34af28b1bf2c4d39ae95a5d25d17f706\n",
      "üß™ View experiment at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 23:00:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/04 23:00:49 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/05/04 23:00:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - F1: 0.8626, Accuracy: 0.8632\n",
      "üèÉ View run RandomForest at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0/runs/639a4d6c86144fbcab73884145ff9006\n",
      "üß™ View experiment at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 23:06:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/04 23:06:45 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/05/04 23:06:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - F1: 0.8737, Accuracy: 0.8736\n",
      "üèÉ View run XGBoost at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0/runs/95a82933d456494984644985dfa5d82b\n",
      "üß™ View experiment at: https://dagshub.com/felytz/waveled.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Model configurations\n",
    "models_config = [\n",
    "    {\n",
    "        \"model\": LogisticRegression(class_weight='balanced', random_state=10, max_iter=1000),\n",
    "        \"name\": \"LogisticRegression_PCA\",\n",
    "        \"params\": {\n",
    "            'C': [0.01, 0.1, 1, 10], \n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"use_pca\": True\n",
    "    },\n",
    "    {\n",
    "        \"model\": LinearSVC(class_weight='balanced', random_state=10, dual=False, max_iter=10000),\n",
    "        \"name\": \"LinearSVC_PCA\",\n",
    "        \"params\": {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l2'],\n",
    "            'loss': ['squared_hinge']\n",
    "        },\n",
    "        \"use_pca\": True\n",
    "    },\n",
    "    {\n",
    "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=10),\n",
    "        \"name\": \"RandomForest\",\n",
    "        \"params\": {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        },\n",
    "        \"use_pca\": False\n",
    "    },\n",
    "    {\n",
    "        \"model\": XGBClassifier(\n",
    "            scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "            random_state=10,\n",
    "            eval_metric='logloss'\n",
    "        ),\n",
    "        \"name\": \"XGBoost\",\n",
    "        \"params\": {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 6],\n",
    "            'subsample': [0.8, 1.0]\n",
    "        },\n",
    "        \"use_pca\": False\n",
    "    }\n",
    "]\n",
    "\n",
    "# Train and register all models\n",
    "for config in models_config:\n",
    "    train_data = X_train_pca if config[\"use_pca\"] else X_train_scaled\n",
    "    val_data = X_val_pca if config[\"use_pca\"] else X_val_scaled\n",
    "    \n",
    "    train_and_register_model(\n",
    "        model=config[\"model\"],\n",
    "        model_name=config[\"name\"],\n",
    "        params=config[\"params\"],\n",
    "        X_train=train_data,\n",
    "        y_train=y_train,\n",
    "        X_test=val_data,\n",
    "        y_test=y_val,\n",
    "        use_pca=config[\"use_pca\"]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
