{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "# base data directory\n",
    "base_dir = '../data/'\n",
    "\n",
    "# raw data directory\n",
    "raw_dir = os.path.join(base_dir, 'raw/')\n",
    "\n",
    "# iterim data directory\n",
    "interim_dir = os.path.join(base_dir, 'interim/')\n",
    "\n",
    "# processed data directory\n",
    "proc_dir =  os.path.join(base_dir, 'processed/')\n",
    "\n",
    "# splits \n",
    "splits = ['bal_train/', 'eval/', 'unbal_train/']\n",
    "\n",
    "# segments files\n",
    "segments = ['balanced_train_segments.csv', 'unbalanced_train_segments.csv', 'eval_segments.csv']\n",
    "\n",
    "# labels file path\n",
    "labels_path = os.path.join(raw_dir, 'class_labels_indices.csv')\n",
    "\n",
    "# onthology file path\n",
    "ont_path = os.path.join(raw_dir, 'ontology.json')\n",
    "\n",
    "# [raw/interim/processed][split]\n",
    "data_path = {'raw': {}, 'interim': {}, 'processed': {}}  \n",
    "\n",
    "# [raw/interim/processed][split]\n",
    "data_dir = {'raw': {}, 'interim': {}, 'processed': {}}  \n",
    "\n",
    "for i, seg in enumerate(splits):\n",
    "    \n",
    "    seg_rm = seg.replace('/', '')\n",
    "    \n",
    "    raw = os.path.join(raw_dir, splits[i])\n",
    "    data_dir['raw'][seg_rm] = raw\n",
    "    raw = os.path.join(raw, segments[i])\n",
    "    data_path['raw'][seg_rm] = raw\n",
    "    \n",
    "    interim = os.path.join(interim_dir, splits[i])\n",
    "    data_dir['interim'][seg_rm] = interim\n",
    "    interim = os.path.join(interim, segments[i])\n",
    "    data_path['interim'][seg_rm] = interim\n",
    "    \n",
    "    processed = os.path.join(proc_dir, splits[i])\n",
    "    data_dir['processed'][seg_rm] = processed\n",
    "    processed = os.path.join(processed, segments[i])\n",
    "    data_path['processed'][seg_rm] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file: ../data/raw/bal_train/balanced_train_segments.csv\n",
      "is in the directory: ../data/raw/bal_train/\n"
     ]
    }
   ],
   "source": [
    "print(f\"data file: {data_path['raw']['bal_train']}\")\n",
    "print(f\"is in the directory: {data_dir['raw']['bal_train']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/bal_train/balanced_train_segments.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path['raw']['bal_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been cleaned and saved in ../data/interim/bal_train/\n"
     ]
    }
   ],
   "source": [
    "# Read the file and replace problematic commas\n",
    "with open(data_path['raw']['bal_train'], \"r\", encoding=\"utf-8\") as f:\n",
    "    # Read all lines from the input file\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    # Remove the first two rows\n",
    "    lines = lines[2:]\n",
    "    \n",
    "    # Remove the first two characters (\"# \") from the third row (now the first row after removing the first two)\n",
    "    lines[0] = lines[0][2:]\n",
    "\n",
    "    # Replace commas that are NOT followed by a space\n",
    "    fixed_lines = [re.sub(r',(?! )', ';', line) for line in lines]\n",
    "\n",
    "# Save the modified file\n",
    "with open(data_path['interim']['bal_train'], \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(fixed_lines)\n",
    "\n",
    "print(f\"File has been cleaned and saved in {data_dir['interim']['bal_train']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--PJHxphWEs</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/m/09x0r;/t/dd00088\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--ZhevVpy1s</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>\"/m/012xff\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--aE2O5G5WE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>\"/m/03fwl;/m/04rlf;/m/09x0r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--aO5cdqSAg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/t/dd00003;/t/dd00005\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--aaILOrkII</td>\n",
       "      <td>200.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>\"/m/032s66;/m/073cg4\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID   start_seconds   end_seconds                positive_labels\n",
       "0  --PJHxphWEs            30.0          40.0          \"/m/09x0r;/t/dd00088\"\n",
       "1  --ZhevVpy1s            50.0          60.0                    \"/m/012xff\"\n",
       "2  --aE2O5G5WE             0.0          10.0   \"/m/03fwl;/m/04rlf;/m/09x0r\"\n",
       "3  --aO5cdqSAg            30.0          40.0        \"/t/dd00003;/t/dd00005\"\n",
       "4  --aaILOrkII           200.0         210.0          \"/m/032s66;/m/073cg4\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: Read the modified file\n",
    "df = pd.read_csv(\n",
    "    data_path['interim']['bal_train'],\n",
    "    quotechar = '\"',\n",
    "    delimiter = \",\",\n",
    "    quoting = 1,\n",
    "    index_col = 0,\n",
    "    header = 0,\n",
    "    dtype = {'positive_labels': str} \n",
    ")\n",
    "\n",
    "# keep the index as a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# drop it\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecord files list for bal_train\n",
    "split_dir = data_dir['raw']['bal_train']\n",
    "tfrecord_files = [os.path.join(split_dir, f) for f in os.listdir(split_dir) if f.endswith('.tfrecord')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_tfrecord_n(file_path, n):\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    for i, raw_record in enumerate(raw_dataset.take(n), start=1):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        print(f\"Features del registro numero {i} de {file_name}:\")\n",
    "        for key, feature in example.features.feature.items():\n",
    "            if feature.HasField(\"bytes_list\"):\n",
    "                value = feature.bytes_list.value[0].decode('utf-8') if feature.bytes_list.value else \"\"\n",
    "            elif feature.HasField(\"float_list\"):\n",
    "                value = feature.float_list.value[0] if feature.float_list.value else 0.0\n",
    "            elif feature.HasField(\"int64_list\"):\n",
    "                value = feature.int64_list.value[0] if feature.int64_list.value else 0\n",
    "            else:\n",
    "                value = \"Unknown Type\"\n",
    "            print(f'\"{key}\": {value}')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inspect an arbitrary record from the tfrecord list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features del registro numero 1 de --.tfrecord:\n",
      "\"labels\": 399\n",
      "\"video_id\": --cB2ZVjpnA\n",
      "\"start_time_seconds\": 30.0\n",
      "\"end_time_seconds\": 40.0\n",
      "\n",
      "Features del registro numero 2 de --.tfrecord:\n",
      "\"end_time_seconds\": 40.0\n",
      "\"video_id\": --PJHxphWEs\n",
      "\"start_time_seconds\": 30.0\n",
      "\"labels\": 0\n",
      "\n",
      "Features del registro numero 3 de --.tfrecord:\n",
      "\"end_time_seconds\": 40.0\n",
      "\"video_id\": --ekDLDTUXA\n",
      "\"start_time_seconds\": 30.0\n",
      "\"labels\": 27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = tfrecord_files[0]\n",
    "inspect_tfrecord_n(file_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YTID</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>end_seconds</th>\n",
       "      <th>positive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--cB2ZVjpnA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>\"/m/01y3hg\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          YTID   start_seconds   end_seconds  positive_labels\n",
       "5  --cB2ZVjpnA            30.0          40.0      \"/m/01y3hg\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = df[df['YTID'].str.contains('--cB2ZVjpnA')] \n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/m/0dgw9r',\n",
       " 'name': 'Human sounds',\n",
       " 'description': 'Sounds produced by the human body through the actions of the individual.',\n",
       " 'citation_uri': '',\n",
       " 'positive_examples': [],\n",
       " 'child_ids': ['/m/09l8g',\n",
       "  '/m/01w250',\n",
       "  '/m/09hlz4',\n",
       "  '/m/0bpl036',\n",
       "  '/m/0160x5',\n",
       "  '/m/0k65p',\n",
       "  '/m/01jg02',\n",
       "  '/m/04xp5v',\n",
       "  '/t/dd00012'],\n",
       " 'restrictions': ['abstract']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Open and read the JSON onthology file\n",
    "with open(ont_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target '/m/01y3hg' was found in the following names: ['Alarm', 'Smoke detector, smoke alarm']\n"
     ]
    }
   ],
   "source": [
    "# Target string to search for\n",
    "target_string = \"/m/01y3hg\"\n",
    "\n",
    "# Function to search for the target string in 'id' and 'child_ids'\n",
    "def search_data(data, target):\n",
    "    results = []\n",
    "    for item in data:\n",
    "        # Check if the target matches the 'id' field\n",
    "        if item['id'] == target:\n",
    "            results.append(item['name'])\n",
    "        # Check if the target matches any of the 'child_ids'\n",
    "        if target in item.get('child_ids', []):\n",
    "            results.append(item['name'])\n",
    "    return results\n",
    "\n",
    "# Perform the search\n",
    "matching_names = search_data(data, target_string)\n",
    "\n",
    "# Print the results\n",
    "if matching_names:\n",
    "    print(f\"The target '{target_string}' was found in the following names: {matching_names}\")\n",
    "else:\n",
    "    print(f\"The target '{target_string}' was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features del registro numero 1 de \"--.tfrecord\", con \"video_id\" de --cB2ZVjpnA tiene en la columna de \"positive_labels\" del archivo segments.csv, un valor de  \"/m/01y3hg\", el cual al buscarlo en el diccionario ontology.json obtenemos que tiene los valores de \"['Alarm', 'Smoke detector, smoke alarm']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un TFRecord es un formato de almacenamiento eficiente de TensorFlow para datos estructurados (imágenes, audio, texto, etc.). Cada archivo TFRecord utilizado en este caso, contiene una serie de ejemplos serializados en formato tf.train.Example (protocol buffer de Google) el cual puede apreciarse en la pagina de descarga de [AudioSet.](https://research.google.com/audioset/download.html)\n",
    "\n",
    "Para poder comprimir a dicho formato diversos archivos de audio, basandonos en [VGGish](https://github.com/tensorflow/models/tree/master/research/audioset/vggish), seccion del repositorio tensorflow de referencia, en el cual se explica como fueron tratados los datos, por lo que definimos las formulas que se utilizaron.\n",
    "\n",
    "Nota: para el correcto funcionamiento de la funcion \"postprocess\", se necesitan descargar \"vggish_pca_params.npy\" y \"vggish_quant_scale.npy\", de [VGGish](https://github.com/tensorflow/models/tree/master/research/audioset/vggish)\n",
    "\n",
    "Nota 2: Tomar en cuenta la version de tensorflow utilizada para este codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vggish_input.py:\n",
    "def waveform_to_examples(waveform, sample_rate):\n",
    "    \"\"\"Convierte audio en un espectrograma de Mel logarítmico.\"\"\"\n",
    "    log_mel = log_mel_spectrogram(\n",
    "        waveform,\n",
    "        sample_rate,\n",
    "        window_size=25e-3,  # 25 ms por ventana\n",
    "        hop_size=10e-3,     # 10 ms de salto entre ventanas\n",
    "        num_mel_bins=64,    # 64 bandas de frecuencia Mel\n",
    "    )\n",
    "    return log_mel  # Shape: [N, 64], donde N depende de la duración del audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import slim  # TensorFlow-Slim (para definir redes compactas)\n",
    "\n",
    "def vggish(inputs):\n",
    "    \"\"\"Red VGGish: CNN que mapea espectrogramas a embeddings de 128-D.\"\"\"\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                       weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                       weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        \n",
    "        # --- Capa 1: Conv2D + ReLU + MaxPool ---\n",
    "        net = slim.conv2d(inputs, 64, [3, 3], scope='conv1')  # 64 filtros 3x3\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool1')     # Reducción a la mitad\n",
    "\n",
    "        # --- Capa 2: Conv2D + ReLU + MaxPool ---\n",
    "        net = slim.conv2d(net, 128, [3, 3], scope='conv2')   # 128 filtros 3x3\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool2')     # Reducción a la mitad\n",
    "\n",
    "        # --- Capa 3: 2x Conv2D + ReLU + MaxPool ---\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3/conv3_1')  # 256 filtros\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(net, 256, [3, 3], scope='conv3/conv3_2')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool3')            # Reducción a la mitad\n",
    "\n",
    "        # --- Capa 4: 2x Conv2D + ReLU + MaxPool ---\n",
    "        net = slim.conv2d(net, 512, [3, 3], scope='conv4/conv4_1')  # 512 filtros\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.conv2d(net, 512, [3, 3], scope='conv4/conv4_2')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool4')            # Reducción a la mitad\n",
    "\n",
    "        # --- Aplanado (Flatten) ---\n",
    "        net = slim.flatten(net)  # Convierte la salida 3D en 1D\n",
    "\n",
    "        # --- Capas Fully Connected (Densas) ---\n",
    "        net = slim.fully_connected(net, 4096, scope='fc1/fc1_1')     # 4096 neuronas\n",
    "        net = tf.nn.relu(net)\n",
    "        net = slim.fully_connected(net, 4096, scope='fc1/fc2_1')     # 4096 neuronas\n",
    "        net = tf.nn.relu(net)\n",
    "\n",
    "        # --- Capa de Salida (Embedding Final) ---\n",
    "        net = slim.fully_connected(net, 128, scope='fc2')            # 128-D\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(embeddings):\n",
    "    \"\"\"Aplica PCA y cuantización a los embeddings.\"\"\"\n",
    "    \"\"\"Para esta funcion se necesita descargar los archivos correspondientes\"\"\"\n",
    "    pca_matrix = np.load('vggish_pca_params.npy')  # Shape: [128, 64]\n",
    "    quant_scale = np.load('vggish_quant_scale.npy')  # Ejemplo: 100.0\n",
    "    processed = np.dot(embeddings, pca_matrix)  # Reduce dimensionalidad\n",
    "    processed = np.round(processed * quant_scale)  # Cuantización\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from vggish_input import waveform_to_examples\n",
    "\n",
    "# Cargar audio (ejemplo con librosa)\n",
    "audio, sr = librosa.load('audio.wav', sr=16000, mono=True)  # 16kHz, mono\n",
    "\n",
    "# Convertir a espectrograma log-Mel (shape: [N, 64])\n",
    "log_mel_examples = waveform_to_examples(audio, sr)\n",
    "\n",
    "import tensorflow as tf\n",
    "from vggish_slim import vggish\n",
    "\n",
    "# Cargar el modelo VGGish preentrenado\n",
    "model = vggish()\n",
    "\n",
    "# Generar embeddings (shape: [N, 128])\n",
    "embeddings = model.predict(log_mel_examples)\n",
    "\n",
    "from vggish_postprocess import Postprocessor\n",
    "\n",
    "postprocessor = Postprocessor()\n",
    "processed_embeddings = postprocessor.postprocess(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo WAV \n",
    "\n",
    "  → [Preprocesamiento] → Espectrograma de Mel (64 bandas) \n",
    "\n",
    "  → [VGGish] → Embedding (128-D) \n",
    "\n",
    "  → [Postprocesamiento] → Embedding cuantizado (opcional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
